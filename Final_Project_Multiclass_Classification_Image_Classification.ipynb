{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7XEpyLiS_Yvf",
        "tmlWhvLC_sUc",
        "5u6pDbOlAybu",
        "4xtif8VvA4Al",
        "Soimv0r7A-2e",
        "pFVhips_BOQG",
        "olek8cK3Bu0F"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MultiClass Image Classification** <br/>\n",
        "#### *An overview of evaluation metrics for a multiclass machine-learning model*"
      ],
      "metadata": {
        "id": "_IZhaagZ9wOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whether it’s spelled multi-class or multiclass, the science is the same. Multiclass image classification is a common task in computer vision, where we categorize an image into three or more classes.\n",
        "\n",
        "We have heard about classification and regression techniques in Machine Learning. We know that these two techniques work on different algorithms for discrete and continuous data respectively. In this article, we will learn more about classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "AdPEX-Vg98r9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Work Flow:<br/>\n",
        "- Scrape Images from Google\n",
        "- Removing duplicated images\n",
        "- Dominate background color\n",
        "- Training a model\n",
        "- Predicting an Image-category\n",
        "- When we can classify an image into more than one class, it is known as a multi-label image classification problem."
      ],
      "metadata": {
        "id": "m-CL4EEb-ncb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Initial Start-ups:**\n"
      ],
      "metadata": {
        "id": "7XEpyLiS_Yvf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW0A81Wb8_cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "e70f4d35-bcfa-473e-b086-79cc1ac9b56d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b2b4587b004f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimple_image_download\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_image_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageStat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simple_image_download'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import csv\n",
        "import glob\n",
        "import pickle\n",
        "import time\n",
        "from simple_image_download import simple_image_download\n",
        "from sklearn.cluster import KMeans\n",
        "from PIL import Image, ImageStat\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array, load_img,   ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a CSV file for the categories you want to download and store that in a project directory. we will be using 16 categories in this project."
      ],
      "metadata": {
        "id": "Jjnuz4vh_kdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Fetch Images from Google**"
      ],
      "metadata": {
        "id": "tmlWhvLC_sUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def images_scrapped_from_google():\n",
        "    number_of_images_download = 100\n",
        "    response = simple_image_download.simple_image_download\n",
        "\n",
        "    with open(load_queries_from_file) as file:\n",
        "        queries = list(x[0] for x in csv.reader(file))\n",
        "       \n",
        "    for query in queries:\n",
        "        response().download(query,number_of_images_download)"
      ],
      "metadata": {
        "id": "FU_xGLzo9Wnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple_image_download is open-source python library, which comes handy in-terms of downloading images from internet and to generate datasets for model training."
      ],
      "metadata": {
        "id": "o9_QTnggAumI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Removing Duplicate Images from folder**"
      ],
      "metadata": {
        "id": "5u6pDbOlAybu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob.glob(os.path.join(os.getcwd(), 'simple_images/*'))\n",
        "\n",
        "images_storing = []\n",
        "duplicated_files = []\n",
        "\n",
        "for folder in folders:\n",
        "    for image in glob.glob(folder + '/*'):\n",
        "        if not image in duplicated_files:\n",
        "            img_org = Image.open(image)\n",
        "            pixel_mean1 = ImageStat.Stat(img_org).mean\n",
        "\n",
        "            for image_2 in glob.glob(folder + '/*'):\n",
        "                if image != image_2:\n",
        "                    img_check = Image.open(image_2)\n",
        "                    pixel_mean2 = ImageStat.Stat(img_check).mean\n",
        "\n",
        "                    if pixel_mean1 == pixel_mean2:\n",
        "                        duplicated_files.append(image)\n",
        "                        duplicated_files.append(image_2)\n",
        "\n",
        "                        try:\n",
        "                            os.remove(image_2)\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                        if not image in images_storing:\n",
        "                            images_storing.append(image)\n",
        "                else:\n",
        "                    if not image in images_storing:\n",
        "                        images_storing.append(image)\n",
        "\n",
        "return images_storing"
      ],
      "metadata": {
        "id": "dGNg9MXa9aX4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "bb1f6034-7a32-4dd3-9061-2f545a0c8972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-08b629675d33>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    return images_storing\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What is glob.glob?**\n",
        "\n",
        "So, it will lets you grab all the files or folders from directory using Regex. For example,"
      ],
      "metadata": {
        "id": "4xtif8VvA4Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob.glob(“simple_images/*”)\n",
        "print(folders)"
      ],
      "metadata": {
        "id": "w4b18ft49hTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3: Finding Dominant Background color**"
      ],
      "metadata": {
        "id": "Soimv0r7A-2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getting_percentage_of_dominant_colors(cluster, centroids):\n",
        "    labels = np.arange(0, len(np.unique(cluster.labels_)) + 1)\n",
        "    (hist, _) = np.histogram(cluster.labels_, bins=labels)\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= hist.sum()\n",
        "\n",
        "    # iterate through each cluster's color and percentage\n",
        "    colors = sorted([(percent, color) for (percent, color) in zip(hist, centroids)])\n",
        "    for (percent, color) in colors:\n",
        "        try:\n",
        "            if percent > 0.50:\n",
        "                print(color, \"{:0.2f}%\".format(percent * 100))\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "    return False"
      ],
      "metadata": {
        "id": "-thUY72q9kDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function will check if an image has a dominant color background > 0.50 then image will be stored otherwise delete it. The reason behind is that when you have a multi color in the background, the object won’t be accurately detected by Model."
      ],
      "metadata": {
        "id": "v_zOWiBuBE5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images and convert to a list of pixels\n",
        "load_images = images_scrapped_from_google()\n",
        "\n",
        "images_for_model_train = []\n",
        "count = 0\n",
        "for img in load_images:\n",
        "    try:\n",
        "        count += 1\n",
        "        print(count)\n",
        "        try:\n",
        "            image = cv2.imread(img)\n",
        "        except Exception:\n",
        "            pass\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        reshape = image.reshape((image.shape[0] * image.shape[1], 3))\n",
        "\n",
        "        # Find and display most dominant colors\n",
        "        kmeans = KMeans(n_clusters=5).fit(reshape)\n",
        "        visualize = getting_percentage_of_dominant_colors(kmeans, kmeans.cluster_centers_)\n",
        "        if visualize is True:\n",
        "            images_for_model_train.append(img)\n",
        "            with open(\"labels_list_of_single_images.csv\", \"w\", newline=\"\") as f:\n",
        "                columns = ['image_path', 'category']\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow(columns)\n",
        "                for img_to_csv in images_for_model_train:\n",
        "                    writer.writerow([img_to_csv, img_to_csv.split(\"\\\\\")[-2]])\n",
        "        else:\n",
        "            try:\n",
        "                os.remove(img)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    except:\n",
        "        print(\"Unrecognized Input of an Image\")\n",
        "        os.remove(img)\n"
      ],
      "metadata": {
        "id": "CUED_UOF9nVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing a CSV file with category, for giving path to model, from where it takes image and getting train on it.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hto6TsP6BISR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4: Load Model for Training**\n",
        "\n",
        "Now we are all set to start coding for our model training. We will be using a pre-trained model InceptionV3 which has been trained on the image data having 1000 classes.\n",
        "\n",
        "Why use a pre-trained CNN model? The initial layers of a CNN train on only low-level and mid-level features such as edges, lines, borders, etc. All kinds of images contain these features in them. These characteristics of a pre-trained CNN makes it very reusable. Hence it makes sense to use such pre-trained models that have been already trained on a large set of data, for which many companies have invested a lot of money.\n",
        "\n"
      ],
      "metadata": {
        "id": "pFVhips_BOQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = pd.read_csv(os.path.join(os.getcwd(), \"labels_list_of_single_images.csv\"))\n",
        "    top_categories = sorted(list(df['category'].value_counts().index))\n",
        "    target_labels = df['category']\n",
        "    train_data = np.array(\n",
        "        [img_to_array(load_img(train_img, target_size=(299, 299))) for train_img in df['image_path'].values.tolist()]) \\\n",
        "        .astype('float32')\n",
        "    x_train, x_validation, y_train, y_validation = train_test_split(train_data, target_labels, test_size=0.2,\n",
        "                                                                    random_state=100)\n",
        "\n",
        "    print(\"x_train samples: \", x_train.shape)\n",
        "    print(\"x_validation samples: \", x_validation.shape)\n",
        "\n",
        "    y_train = pd.get_dummies(y_train.reset_index(drop=True)).values\n",
        "    y_validation = pd.get_dummies(y_validation.reset_index(drop=True)).values\n",
        "\n",
        "    # Train Generator\n",
        "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                       rotation_range=30,\n",
        "                                       width_shift_range=0.2,\n",
        "                                       height_shift_range=0.2,\n",
        "                                       horizontal_flip='true')\n",
        "\n",
        "    train_generator = train_datagen.flow(x_train, y_train, shuffle=False, batch_size=40, seed=42)\n",
        "\n",
        "    # Validation Generator\n",
        "    val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    val_generator = val_datagen.flow(x_validation, y_validation, shuffle=False, batch_size=40, seed=42)\n",
        "\n",
        "\n",
        "# Model Intialize\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Add a fully-connected layer\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    predictions = Dense(16, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    model.compile(Adam(lr=.0001), loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    start = time.time()\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=len(x_train) // 40,\n",
        "                        validation_data=val_generator,\n",
        "                        validation_steps=len(x_validation) // 40,\n",
        "                        epochs=5,\n",
        "                        verbose=2)\n",
        "    end = time.time()\n",
        "    print(\"\\nTotal Time Taken:\", round((end - start) / 60, 2), \"Minutes\")\n",
        "\n",
        "    try:\n",
        "        file = open(\"multi_class_model.pkl\", \"wb\")\n",
        "        pickle.dump(model, file)\n",
        "        print(\"Model Saved..!!\")\n",
        "       \n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "except Exception as e:\n",
        "    print(str(e))"
      ],
      "metadata": {
        "id": "CYwWT9o49rC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning:**\n",
        "\n",
        "To use a pre-trained model we need to keep all the previous layers as is and change only the final layer according to our use case. InceptionV3 has been trained on 1000 image classes. Our problem has only 16 different image classes. Hence, we will modify the last layer of InceptionV3 to 16 classes. Transfer Learning saves a lot of training time and development effort of the engineers.\n",
        "\n",
        "ImageDataGenerator works for augmented the images. We can do a lot more preprocessing for data augmentations. Neural networks work better with a lot of data. Data augmentation is a strategy which we use at training time to increase the amount of data we have."
      ],
      "metadata": {
        "id": "zae5YzF8BrMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5: Predicting a image category**"
      ],
      "metadata": {
        "id": "olek8cK3Bu0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Prediction\n",
        "def predict_from_image(img_path):\n",
        "    model_classes = pickle.load(open(\"multi_class_model.pkl\", \"rb\"))\n",
        "    print(model_classes.summary())\n",
        "    img = image.load_img(img_path, target_size=(299, 299))\n",
        "    img_tensor = image.img_to_array(img)  # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor,\n",
        "                                axis=0)  # (1, height, width, channels),\n",
        "                  #add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.\n",
        "\n",
        "    pred = model_classes.predict(img_tensor)\n",
        "    sorted_category_list = sorted(top_categories)\n",
        "    predicted_class = sorted_category_list[np.argmax(pred)]\n",
        "\n",
        "    return predicted_class, max(pred)\n",
        "\n",
        "\n",
        "img_path = os.path.join(os.getcwd(), \"baseball bat_3.jpg\")\n",
        "classes, prob = predict_from_image(img_path)\n",
        "print(f\"\\n{classes}\\n{prob[top_categories.index(classes)]}\")"
      ],
      "metadata": {
        "id": "uECjAk7y9uBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseball_bat\n",
        "# Output :  0.9999959468841553"
      ],
      "metadata": {
        "id": "cwS6jxvvCBjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have now successfully built a CNN model using Transfer Learning. With this approach, any Multi-class Image Classification problem can be tackled with good accuracy in a short span of time.\n",
        "\n",
        "Happy Learning…!!!\n",
        "\n",
        "Source : https://medium.com/geekculture/multiclass-image-classification-dcf9585f2ff9#:~:text=Multiclass%20image%20classification%20is%20a,discrete%20and%20continuous%20data%20respectively."
      ],
      "metadata": {
        "id": "kZGb9aXKB6vT"
      }
    }
  ]
}